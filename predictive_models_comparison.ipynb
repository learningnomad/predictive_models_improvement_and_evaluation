{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Rating Prdeiction- Classification Models using Logistic Regression and Naive Bayes\n",
    "### Background\n",
    "\n",
    "The German Credit Card data set is for customers of a financial institution who have been labeled as “good” or “bad” credit risks (in fact: whether they repaid the loan or did not repay the loan). The dataset contains 21 attributes (20 predictors and one dependent variable) and 1000 instances, with no missing values (the data are real, but were cleaned up before being put into the archive). The specification of these attributes is given in the document `german.doc`.\n",
    "\n",
    "We will build two classification models using logistic regression and naive bayes to report their performance metrics. We will use the first 800 rows as the training data and the rest of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "Warning message:\n",
      "\"package 'e1071' was built under R version 3.4.4\"Warning message:\n",
      "\"package 'ROCR' was built under R version 3.4.4\"Loading required package: gplots\n",
      "Warning message:\n",
      "\"package 'gplots' was built under R version 3.4.4\"\n",
      "Attaching package: 'gplots'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    lowess\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "## The followings are just suggestions.\n",
    "## You may choose to use different libraries\n",
    "library(caret) # for confusion matrix and other stats\n",
    "library(e1071) # for naiveBayes\n",
    "library(ROCR)\n",
    "library(ggplot2)\n",
    "\n",
    "# load data\n",
    "df = read.table(\"german.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th><th scope=col>V6</th><th scope=col>V7</th><th scope=col>V8</th><th scope=col>V9</th><th scope=col>V10</th><th scope=col>...</th><th scope=col>V12</th><th scope=col>V13</th><th scope=col>V14</th><th scope=col>V15</th><th scope=col>V16</th><th scope=col>V17</th><th scope=col>V18</th><th scope=col>V19</th><th scope=col>V20</th><th scope=col>V21</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>A11 </td><td> 6  </td><td>A34 </td><td>A43 </td><td>1169</td><td>A65 </td><td>A75 </td><td>4   </td><td>A93 </td><td>A101</td><td>... </td><td>A121</td><td>67  </td><td>A143</td><td>A152</td><td>2   </td><td>A173</td><td>1   </td><td>A192</td><td>A201</td><td>1   </td></tr>\n",
       "\t<tr><td>A12 </td><td>48  </td><td>A32 </td><td>A43 </td><td>5951</td><td>A61 </td><td>A73 </td><td>2   </td><td>A92 </td><td>A101</td><td>... </td><td>A121</td><td>22  </td><td>A143</td><td>A152</td><td>1   </td><td>A173</td><td>1   </td><td>A191</td><td>A201</td><td>2   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       " V1 & V2 & V3 & V4 & V5 & V6 & V7 & V8 & V9 & V10 & ... & V12 & V13 & V14 & V15 & V16 & V17 & V18 & V19 & V20 & V21\\\\\n",
       "\\hline\n",
       "\t A11  &  6   & A34  & A43  & 1169 & A65  & A75  & 4    & A93  & A101 & ...  & A121 & 67   & A143 & A152 & 2    & A173 & 1    & A192 & A201 & 1   \\\\\n",
       "\t A12  & 48   & A32  & A43  & 5951 & A61  & A73  & 2    & A92  & A101 & ...  & A121 & 22   & A143 & A152 & 1    & A173 & 1    & A191 & A201 & 2   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "V1 | V2 | V3 | V4 | V5 | V6 | V7 | V8 | V9 | V10 | ... | V12 | V13 | V14 | V15 | V16 | V17 | V18 | V19 | V20 | V21 | \n",
       "|---|---|\n",
       "| A11  |  6   | A34  | A43  | 1169 | A65  | A75  | 4    | A93  | A101 | ...  | A121 | 67   | A143 | A152 | 2    | A173 | 1    | A192 | A201 | 1    | \n",
       "| A12  | 48   | A32  | A43  | 5951 | A61  | A73  | 2    | A92  | A101 | ...  | A121 | 22   | A143 | A152 | 1    | A173 | 1    | A191 | A201 | 2    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  V1  V2 V3  V4  V5   V6  V7  V8 V9  V10  ... V12  V13 V14  V15  V16 V17  V18\n",
       "1 A11  6 A34 A43 1169 A65 A75 4  A93 A101 ... A121 67  A143 A152 2   A173 1  \n",
       "2 A12 48 A32 A43 5951 A61 A73 2  A92 A101 ... A121 22  A143 A152 1   A173 1  \n",
       "  V19  V20  V21\n",
       "1 A192 A201 1  \n",
       "2 A191 A201 2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's have a look at the data set.\n",
    "\n",
    "head(df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We change the variable names to more meaningful names\n",
    "\n",
    "colnames(df) <- c('status_checking_acct', 'duration_months', 'credit_hist', 'purpose', 'credit_amt', 'savings_acct',\n",
    "                       'employment', 'installment_rate', 'sex_status', 'other_debtors', 'residence', 'property', 'age',\n",
    "                       'other_installment_plans', 'housing', 'existing_crdits', 'job', 'liability_to_other_people',\n",
    "                       'telephone', 'foreign_worker', 'credit_risk'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1000 obs. of  21 variables:\n",
      " $ status_checking_acct     : Factor w/ 4 levels \"A11\",\"A12\",\"A13\",..: 1 2 4 1 1 4 4 2 4 2 ...\n",
      " $ duration_months          : int  6 48 12 42 24 36 24 36 12 30 ...\n",
      " $ credit_hist              : Factor w/ 5 levels \"A30\",\"A31\",\"A32\",..: 5 3 5 3 4 3 3 3 3 5 ...\n",
      " $ purpose                  : Factor w/ 10 levels \"A40\",\"A41\",\"A410\",..: 5 5 8 4 1 8 4 2 5 1 ...\n",
      " $ credit_amt               : int  1169 5951 2096 7882 4870 9055 2835 6948 3059 5234 ...\n",
      " $ savings_acct             : Factor w/ 5 levels \"A61\",\"A62\",\"A63\",..: 5 1 1 1 1 5 3 1 4 1 ...\n",
      " $ employment               : Factor w/ 5 levels \"A71\",\"A72\",\"A73\",..: 5 3 4 4 3 3 5 3 4 1 ...\n",
      " $ installment_rate         : int  4 2 2 2 3 2 3 2 2 4 ...\n",
      " $ sex_status               : Factor w/ 4 levels \"A91\",\"A92\",\"A93\",..: 3 2 3 3 3 3 3 3 1 4 ...\n",
      " $ other_debtors            : Factor w/ 3 levels \"A101\",\"A102\",..: 1 1 1 3 1 1 1 1 1 1 ...\n",
      " $ residence                : int  4 2 3 4 4 4 4 2 4 2 ...\n",
      " $ property                 : Factor w/ 4 levels \"A121\",\"A122\",..: 1 1 1 2 4 4 2 3 1 3 ...\n",
      " $ age                      : int  67 22 49 45 53 35 53 35 61 28 ...\n",
      " $ other_installment_plans  : Factor w/ 3 levels \"A141\",\"A142\",..: 3 3 3 3 3 3 3 3 3 3 ...\n",
      " $ housing                  : Factor w/ 3 levels \"A151\",\"A152\",..: 2 2 2 3 3 3 2 1 2 2 ...\n",
      " $ existing_crdits          : int  2 1 1 1 2 1 1 1 1 2 ...\n",
      " $ job                      : Factor w/ 4 levels \"A171\",\"A172\",..: 3 3 2 3 3 2 3 4 2 4 ...\n",
      " $ liability_to_other_people: int  1 1 2 2 2 2 1 1 1 1 ...\n",
      " $ telephone                : Factor w/ 2 levels \"A191\",\"A192\": 2 1 1 1 1 2 1 2 1 1 ...\n",
      " $ foreign_worker           : Factor w/ 2 levels \"A201\",\"A202\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ credit_risk              : int  1 2 1 1 2 1 1 1 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "# we check that our changes has been applied successfully and inspect the structure of the data\n",
    "\n",
    "str(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We change credit risk response variable values from 1 and 2 to 0 and 1, respectively.\n",
    "\n",
    "df$credit_risk[df$credit_risk == 1] <- 0 # change 1 to 0\n",
    "df$credit_risk[df$credit_risk == 2] <- 1 # change 2 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:1000] 0 1 0 0 1 0 0 0 0 1 ...\n"
     ]
    }
   ],
   "source": [
    "# we check that the values has been updated successfully.\n",
    "\n",
    "str(df$credit_risk, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we change the levels to more meaningful names \n",
    "\n",
    "df$credit_risk <- as.factor(df$credit_risk)\n",
    "levels(df$credit_risk) <- c('Good Credit Risk', 'Bad Credit Risk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1:\n",
    "We will build a logistic regression and a naive bayes model using all predictors. We will report their efficiency regarding precision, recall, and F1 score using the test data. We will compare the two models and explain our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we divide the data set into 2, a training set and a test set\n",
    "\n",
    "trainSet = df[1:800, ]\n",
    "testSet = df[801:1000, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model using all predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Building and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# building the logistic regression model\n",
    "# we will use the train() function from the caret library to build and train our logistic regression model\n",
    "#  the first argument 'crdit_risk' is our response variable and '.' denotes that we want to use all other variables as predictors\n",
    "#  the second argument 'trainSet' is the data we would like to use to train our model,\n",
    "#  the third argument 'method = glm' tells the function the we would like to use generalised linear models\n",
    "#  and the last argument 'family = binomial' tells the function that we would like to use logistic regression\n",
    "\n",
    "logistic_model <- train(credit_risk ~ ., data = trainSet, method = 'glm', family = binomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing the model predict() function\n",
    "#  the first argument is the model type\n",
    "#  the secind arguments is the test data\n",
    "\n",
    "logistic_predict <- predict(logistic_model, newdata=testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "**Model Metrics/ Efficiency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  Predicted\n",
       "Actual             Good Credit Risk Bad Credit Risk\n",
       "  Good Credit Risk              115              24\n",
       "  Bad Credit Risk                29              32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we build a confusion matrix based on actual testSet data and the prediction data\n",
    "\n",
    "confusion.matrix <- as.matrix(table('Actual'=testSet$credit_risk, 'Predicted'=logistic_predict))\n",
    "confusion.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the confusion matrix that 115 of good credit risk and 32 of bad credit risk observations were correctly predicted.<br> 115 + 24 represents True Positive (TP) and 29 + 32 represents True Negative (TN).<br>\n",
    "On the other hand, 29 bad credit risk and 24 good credit risk observations were incorrectly predicted.<br>\n",
    "29 represents False Positive (FP) and 24 represents False Negative (FN).<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Precision**<br><br>\n",
    "$Precision = \\frac{True\\space Positives}{True\\space Positives + False\\space Positives}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Precision metric of our logistic regression model = 0.8274'"
      ],
      "text/latex": [
       "'Precision metric of our logistic regression model = 0.8274'"
      ],
      "text/markdown": [
       "'Precision metric of our logistic regression model = 0.8274'"
      ],
      "text/plain": [
       "[1] \"Precision metric of our logistic regression model = 0.8274\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# true positive from confusion matrix\n",
    "\n",
    "tp <- sum(confusion.matrix[1,])\n",
    "\n",
    "# true positives + false positives from confusion matrix \n",
    "\n",
    "tp_fp <- sum(confusion.matrix[1,], confusion.matrix[2,1])\n",
    "\n",
    "# compute the precision from above formula for precision\n",
    "\n",
    "precision <- tp / tp_fp\n",
    "paste('Precision metric of our logistic regression model =', round(precision, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8274 of all samples predicted by our model as positive were really positive.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Recall**<br><br>\n",
    "$Recall = \\frac{True\\space Positives}{True\\space Positives + False\\space Negatives}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Recall metric of our logistic regression model = 0.8528'"
      ],
      "text/latex": [
       "'Recall metric of our logistic regression model = 0.8528'"
      ],
      "text/markdown": [
       "'Recall metric of our logistic regression model = 0.8528'"
      ],
      "text/plain": [
       "[1] \"Recall metric of our logistic regression model = 0.8528\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# true positives + false negatives\n",
    "\n",
    "tp_fn <- sum(confusion.matrix[1,], confusion.matrix[1,2])\n",
    "\n",
    "# compute recall from above formula\n",
    "\n",
    "recall <- tp / tp_fn\n",
    "paste('Recall metric of our logistic regression model =', round(recall, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8528 of all positive samples were predicted positive by our model.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate F Score**<br><br>\n",
    "$F1= 2\\times\\frac{precision \\space\\times\\space recall}{precision\\space+ \\space recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'F Score of our logistic regression model = 0.8399'"
      ],
      "text/latex": [
       "'F Score of our logistic regression model = 0.8399'"
      ],
      "text/markdown": [
       "'F Score of our logistic regression model = 0.8399'"
      ],
      "text/plain": [
       "[1] \"F Score of our logistic regression model = 0.8399\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute F score from above formula\n",
    "f1 <- 2 * (precision * recall) / (precision + recall)\n",
    "paste('F Score of our logistic regression model =', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Building and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the Naive Bayes model\n",
    "# we use tthe naiveBayes()function from the e1071 library to build our model\n",
    "# the first argument 'crdit_risk' is our response variable and '.' denotes that we want to use all other variables as predictors\n",
    "# the second argument is the training data\n",
    "\n",
    "nb_model <- naiveBayes(credit_risk ~ ., data = trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing the model predict() function\n",
    "#  the first argument is the model type\n",
    "#  the secind arguments is the test data \n",
    "\n",
    "nb_predict <- predict(nb_model, testSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Metrics/ Efficiency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  Predicted\n",
       "Actual             Good Credit Risk Bad Credit Risk\n",
       "  Good Credit Risk              122              17\n",
       "  Bad Credit Risk                25              36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we build a confusion matrix based on actual testSet data and the prediction data\n",
    "\n",
    "confusion.matrix <- as.matrix(table('Actual'=testSet$credit_risk, 'Predicted'=nb_predict))\n",
    "confusion.matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the confusion matrix that 122 of good credit risk and 36 of bad credit risk observations were correctly predicted.<br>\n",
    "122 + 17 represents True Positive (TP) and 15 + 36 represents True Negative (TN).<br>\n",
    "On the other hand, 17 good credit risk and 25 bad credit risk observations were incorrectly predicted.<br>\n",
    "25 represents False Positive (FP) and 17 represents False Negative (FN).<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Precision**<br><br>\n",
    "$Precision = \\frac{True\\space Positives}{True\\space Positives + False\\space Positives}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Precision metric of our naive bayes model = 0.8476'"
      ],
      "text/latex": [
       "'Precision metric of our naive bayes model = 0.8476'"
      ],
      "text/markdown": [
       "'Precision metric of our naive bayes model = 0.8476'"
      ],
      "text/plain": [
       "[1] \"Precision metric of our naive bayes model = 0.8476\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# true positive from confusion matrix\n",
    "\n",
    "tp <- sum(confusion.matrix[1,])\n",
    "\n",
    "# true positives + false positives from confusion matrix \n",
    "\n",
    "tp_fp <- sum(confusion.matrix[1,], confusion.matrix[2,1])\n",
    "\n",
    "# compute the precision from above formula\n",
    "\n",
    "precision <- tp / tp_fp\n",
    "paste('Precision metric of our naive bayes model =', round(precision, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8476 of all samples predicted by our model as positive were really positive.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Recall**<br><br>\n",
    "$Recall = \\frac{True\\space Positives}{True\\space Positives + False\\space Negatives}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Recall metric of our naive bayes model = 0.891'"
      ],
      "text/latex": [
       "'Recall metric of our naive bayes model = 0.891'"
      ],
      "text/markdown": [
       "'Recall metric of our naive bayes model = 0.891'"
      ],
      "text/plain": [
       "[1] \"Recall metric of our naive bayes model = 0.891\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# true positives + false negatives\n",
    "\n",
    "tp_fn <- sum(confusion.matrix[1,], confusion.matrix[1,2])\n",
    "\n",
    "# compute recall from above formula\n",
    "\n",
    "recall <- tp / tp_fn\n",
    "paste('Recall metric of our naive bayes model =', round(recall, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.891 of all positive samples were predicted positive by our model.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate F score**<br><br>\n",
    "$F1= 2\\times\\frac{precision \\space\\times\\space recall}{precision\\space+ \\space recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'F Score of our naive bayes model = 0.8688'"
      ],
      "text/latex": [
       "'F Score of our naive bayes model = 0.8688'"
      ],
      "text/markdown": [
       "'F Score of our naive bayes model = 0.8688'"
      ],
      "text/plain": [
       "[1] \"F Score of our naive bayes model = 0.8688\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute F score from above formula\n",
    "\n",
    "f1 <- 2 * (precision * recall) / (precision + recall)\n",
    "paste('F Score of our naive bayes model =', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "** Comparison of the two models and our findings **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Metric|Logistic Regression model|Naive Bayes Model|\n",
    "|---------|-----------------|-------------------------|\n",
    "|Precision|0.8274|0.8476|\n",
    "|Recall   |0.8528|0.8910|\n",
    "|F Score  |0.8399|0.8688|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the metric comparison table above that the Naive Bayes Model is more efficient compared to Logistic Regression when we use all the features that are available in our data set.<br>\n",
    "* Our naive bayes model has better precision compared to our logistic regression model since 0.8476 of the samples predicted by our naive bayes model as 'Good credit risks' were really 'Good credit risks' compared to that of our logistic regression model which is only 0.8274.\n",
    "* Our naive bayes model has better recall compared to our logistic regression model since 0.8910 of all 'Good credit risks' samples were predicted as 'Good credit risks' compared to our logistic regression model which is only 0.8528.\n",
    "* Consequently, since both precision and recall of our naive bayes model is higher than our logistic regression model, the F-score of our naive bayes model is also better than that of our logistic regression model, with 0.8688 for naive bayes and 0.8399 for logistic regression.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2:\n",
    "Based on the summaries of the two models built in (1), we will select a subset of\n",
    "variables that could achieve the same or better performance (in one or more metrics) than the model made above using all predictors. We will then report the new models' performance regarding precision, recall, and F1 score. We will also discuss why having a model with less number of attributes is beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving logistic regression  model by selecting features that are more significant, by using p-values <= 0.05\n",
    "Based on the summary of the logistic regression model that we built earlier, we look at the p-values to select features that are more significant than the others.\n",
    "<br>There are functions that can be used such as varImp() that automatically selects important features but we will not use these automated methods.\n",
    "<br>\n",
    "\n",
    "Reference: Bursac, Z., Gauss, C. H., Williams, D. K., & Hosmer, D. W. (2008). Purposeful selection of variables in logistic regression. Source Code for Biology and Medicine, 3, 17. http://doi.org/10.1186/1751-0473-3-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>status_checking_acctA13</dt>\n",
       "\t\t<dd>0.0205665327688117</dd>\n",
       "\t<dt>status_checking_acctA14</dt>\n",
       "\t\t<dd>1.01600104676918e-10</dd>\n",
       "\t<dt>duration_months</dt>\n",
       "\t\t<dd>0.00547916414404742</dd>\n",
       "\t<dt>credit_histA34</dt>\n",
       "\t\t<dd>0.00243994187562923</dd>\n",
       "\t<dt>purposeA41</dt>\n",
       "\t\t<dd>3.46383072492366e-05</dd>\n",
       "\t<dt>purposeA42</dt>\n",
       "\t\t<dd>0.0017265445857829</dd>\n",
       "\t<dt>purposeA43</dt>\n",
       "\t\t<dd>0.00123577727396886</dd>\n",
       "\t<dt>purposeA49</dt>\n",
       "\t\t<dd>0.0297596645935037</dd>\n",
       "\t<dt>credit_amt</dt>\n",
       "\t\t<dd>0.02768229777293</dd>\n",
       "\t<dt>savings_acctA64</dt>\n",
       "\t\t<dd>0.0255915413756812</dd>\n",
       "\t<dt>savings_acctA65</dt>\n",
       "\t\t<dd>0.0154615584514642</dd>\n",
       "\t<dt>employmentA74</dt>\n",
       "\t\t<dd>0.0306228021827614</dd>\n",
       "\t<dt>installment_rate</dt>\n",
       "\t\t<dd>0.000287438807885747</dd>\n",
       "\t<dt>sex_statusA93</dt>\n",
       "\t\t<dd>0.00376942038236364</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[status\\textbackslash{}\\_checking\\textbackslash{}\\_acctA13] 0.0205665327688117\n",
       "\\item[status\\textbackslash{}\\_checking\\textbackslash{}\\_acctA14] 1.01600104676918e-10\n",
       "\\item[duration\\textbackslash{}\\_months] 0.00547916414404742\n",
       "\\item[credit\\textbackslash{}\\_histA34] 0.00243994187562923\n",
       "\\item[purposeA41] 3.46383072492366e-05\n",
       "\\item[purposeA42] 0.0017265445857829\n",
       "\\item[purposeA43] 0.00123577727396886\n",
       "\\item[purposeA49] 0.0297596645935037\n",
       "\\item[credit\\textbackslash{}\\_amt] 0.02768229777293\n",
       "\\item[savings\\textbackslash{}\\_acctA64] 0.0255915413756812\n",
       "\\item[savings\\textbackslash{}\\_acctA65] 0.0154615584514642\n",
       "\\item[employmentA74] 0.0306228021827614\n",
       "\\item[installment\\textbackslash{}\\_rate] 0.000287438807885747\n",
       "\\item[sex\\textbackslash{}\\_statusA93] 0.00376942038236364\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "status_checking_acctA13\n",
       ":   0.0205665327688117status_checking_acctA14\n",
       ":   1.01600104676918e-10duration_months\n",
       ":   0.00547916414404742credit_histA34\n",
       ":   0.00243994187562923purposeA41\n",
       ":   3.46383072492366e-05purposeA42\n",
       ":   0.0017265445857829purposeA43\n",
       ":   0.00123577727396886purposeA49\n",
       ":   0.0297596645935037credit_amt\n",
       ":   0.02768229777293savings_acctA64\n",
       ":   0.0255915413756812savings_acctA65\n",
       ":   0.0154615584514642employmentA74\n",
       ":   0.0306228021827614installment_rate\n",
       ":   0.000287438807885747sex_statusA93\n",
       ":   0.00376942038236364\n",
       "\n"
      ],
      "text/plain": [
       "status_checking_acctA13 status_checking_acctA14         duration_months \n",
       "           2.056653e-02            1.016001e-10            5.479164e-03 \n",
       "         credit_histA34              purposeA41              purposeA42 \n",
       "           2.439942e-03            3.463831e-05            1.726545e-03 \n",
       "             purposeA43              purposeA49              credit_amt \n",
       "           1.235777e-03            2.975966e-02            2.768230e-02 \n",
       "        savings_acctA64         savings_acctA65           employmentA74 \n",
       "           2.559154e-02            1.546156e-02            3.062280e-02 \n",
       "       installment_rate           sex_statusA93 \n",
       "           2.874388e-04            3.769420e-03 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we get the features whose p-values are < 0.05 from the output of the summary() function for our logistic regression model\n",
    "\n",
    "(summary(logistic_model)$coef[,'Pr(>|z|)'])[(summary(logistic_model)$coef[,'Pr(>|z|)'] < 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will start to build an improved logistic model based on variables above\n",
    "# we then remove each variable at a time to see how the efficiency is affected.\n",
    "# we find that further removing 'sex_status' in the model improved the metrics so we also excluded it in our improved model\n",
    "\n",
    "improved_logistic_model <- train(credit_risk ~ status_checking_acct + duration_months + credit_hist + purpose +\n",
    "                                   credit_amt + savings_acct + employment + installment_rate,\n",
    "                                   data = trainSet, method = 'glm', family = binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing the model\n",
    "\n",
    "improved_logistic_predict <- predict(improved_logistic_model, newdata=testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  Predicted\n",
       "Actual             Good Credit Risk Bad Credit Risk\n",
       "  Good Credit Risk              121              18\n",
       "  Bad Credit Risk                30              31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let us look at the confusion matrix\n",
    "\n",
    "confusion.matrix <- as.matrix(table('Actual'=testSet$credit_risk, 'Predicted' = improved_logistic_predict))\n",
    "confusion.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Precision metric of our improved logistic regression model = 0.8225'"
      ],
      "text/latex": [
       "'Precision metric of our improved logistic regression model = 0.8225'"
      ],
      "text/markdown": [
       "'Precision metric of our improved logistic regression model = 0.8225'"
      ],
      "text/plain": [
       "[1] \"Precision metric of our improved logistic regression model = 0.8225\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Recall metric of our improved logistic regression model = 0.8854'"
      ],
      "text/latex": [
       "'Recall metric of our improved logistic regression model = 0.8854'"
      ],
      "text/markdown": [
       "'Recall metric of our improved logistic regression model = 0.8854'"
      ],
      "text/plain": [
       "[1] \"Recall metric of our improved logistic regression model = 0.8854\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'F Score of our improved logistic regression model = 0.8528'"
      ],
      "text/latex": [
       "'F Score of our improved logistic regression model = 0.8528'"
      ],
      "text/markdown": [
       "'F Score of our improved logistic regression model = 0.8528'"
      ],
      "text/plain": [
       "[1] \"F Score of our improved logistic regression model = 0.8528\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### compute the metrics\n",
    "\n",
    "# true positive\n",
    "tp <- sum(confusion.matrix[1,])\n",
    "\n",
    "# true positives + false positives\n",
    "tp_fp <- sum(confusion.matrix[1,], confusion.matrix[2,1])\n",
    "\n",
    "# compute the precision from above formula\n",
    "precision <- tp / tp_fp\n",
    "paste('Precision metric of our improved logistic regression model =', round(precision, 4))\n",
    "\n",
    "# true positives + false negatives\n",
    "tp_fn <- sum(confusion.matrix[1,], confusion.matrix[1,2])\n",
    "\n",
    "# compute recall from above formula\n",
    "recall <- tp / tp_fn\n",
    "paste('Recall metric of our improved logistic regression model =', round(recall, 4))\n",
    "\n",
    "# compute F score from above formula\n",
    "f1 <- 2 * (precision * recall) / (precision + recall)\n",
    "paste('F Score of our improved logistic regression model =', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Metric|Original Logistic Regression model|Improved Logistic Regression Model|\n",
    "|---------|-----------------|-------------------------|\n",
    "|Precision|0.8274|0.8225|\n",
    "|Recall   |0.8528|0.8854|\n",
    "|F Score  |0.8399|0.8528|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above table that by selecting a subset of the available features based on p-values < 0.05 that our logistic model has improved recall from 0.8528 to 0.8854, as well as F score from 0.8399\tto 0.8528.<br>\n",
    "However, the precision metric went lower, meaning the model has become more pessimistic with more false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving logistic regression model efficiency by adding more features with 0.05 > p-values <  0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>status_checking_acctA13</dt>\n",
       "\t\t<dd>0.0205665327688117</dd>\n",
       "\t<dt>status_checking_acctA14</dt>\n",
       "\t\t<dd>1.01600104676918e-10</dd>\n",
       "\t<dt>duration_months</dt>\n",
       "\t\t<dd>0.00547916414404742</dd>\n",
       "\t<dt>credit_histA33</dt>\n",
       "\t\t<dd>0.0796267227307552</dd>\n",
       "\t<dt>credit_histA34</dt>\n",
       "\t\t<dd>0.00243994187562923</dd>\n",
       "\t<dt>purposeA41</dt>\n",
       "\t\t<dd>3.46383072492366e-05</dd>\n",
       "\t<dt>purposeA410</dt>\n",
       "\t\t<dd>0.0873264979159381</dd>\n",
       "\t<dt>purposeA42</dt>\n",
       "\t\t<dd>0.0017265445857829</dd>\n",
       "\t<dt>purposeA43</dt>\n",
       "\t\t<dd>0.00123577727396886</dd>\n",
       "\t<dt>purposeA48</dt>\n",
       "\t\t<dd>0.0693645902302464</dd>\n",
       "\t<dt>purposeA49</dt>\n",
       "\t\t<dd>0.0297596645935037</dd>\n",
       "\t<dt>credit_amt</dt>\n",
       "\t\t<dd>0.02768229777293</dd>\n",
       "\t<dt>savings_acctA64</dt>\n",
       "\t\t<dd>0.0255915413756812</dd>\n",
       "\t<dt>savings_acctA65</dt>\n",
       "\t\t<dd>0.0154615584514642</dd>\n",
       "\t<dt>employmentA74</dt>\n",
       "\t\t<dd>0.0306228021827614</dd>\n",
       "\t<dt>installment_rate</dt>\n",
       "\t\t<dd>0.000287438807885747</dd>\n",
       "\t<dt>sex_statusA93</dt>\n",
       "\t\t<dd>0.00376942038236364</dd>\n",
       "\t<dt>other_debtorsA103</dt>\n",
       "\t\t<dd>0.0534229330140778</dd>\n",
       "\t<dt>age</dt>\n",
       "\t\t<dd>0.0766817468202007</dd>\n",
       "\t<dt>liability_to_other_people</dt>\n",
       "\t\t<dd>0.0759716500377071</dd>\n",
       "\t<dt>foreign_workerA202</dt>\n",
       "\t\t<dd>0.0637794534482211</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[status\\textbackslash{}\\_checking\\textbackslash{}\\_acctA13] 0.0205665327688117\n",
       "\\item[status\\textbackslash{}\\_checking\\textbackslash{}\\_acctA14] 1.01600104676918e-10\n",
       "\\item[duration\\textbackslash{}\\_months] 0.00547916414404742\n",
       "\\item[credit\\textbackslash{}\\_histA33] 0.0796267227307552\n",
       "\\item[credit\\textbackslash{}\\_histA34] 0.00243994187562923\n",
       "\\item[purposeA41] 3.46383072492366e-05\n",
       "\\item[purposeA410] 0.0873264979159381\n",
       "\\item[purposeA42] 0.0017265445857829\n",
       "\\item[purposeA43] 0.00123577727396886\n",
       "\\item[purposeA48] 0.0693645902302464\n",
       "\\item[purposeA49] 0.0297596645935037\n",
       "\\item[credit\\textbackslash{}\\_amt] 0.02768229777293\n",
       "\\item[savings\\textbackslash{}\\_acctA64] 0.0255915413756812\n",
       "\\item[savings\\textbackslash{}\\_acctA65] 0.0154615584514642\n",
       "\\item[employmentA74] 0.0306228021827614\n",
       "\\item[installment\\textbackslash{}\\_rate] 0.000287438807885747\n",
       "\\item[sex\\textbackslash{}\\_statusA93] 0.00376942038236364\n",
       "\\item[other\\textbackslash{}\\_debtorsA103] 0.0534229330140778\n",
       "\\item[age] 0.0766817468202007\n",
       "\\item[liability\\textbackslash{}\\_to\\textbackslash{}\\_other\\textbackslash{}\\_people] 0.0759716500377071\n",
       "\\item[foreign\\textbackslash{}\\_workerA202] 0.0637794534482211\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "status_checking_acctA13\n",
       ":   0.0205665327688117status_checking_acctA14\n",
       ":   1.01600104676918e-10duration_months\n",
       ":   0.00547916414404742credit_histA33\n",
       ":   0.0796267227307552credit_histA34\n",
       ":   0.00243994187562923purposeA41\n",
       ":   3.46383072492366e-05purposeA410\n",
       ":   0.0873264979159381purposeA42\n",
       ":   0.0017265445857829purposeA43\n",
       ":   0.00123577727396886purposeA48\n",
       ":   0.0693645902302464purposeA49\n",
       ":   0.0297596645935037credit_amt\n",
       ":   0.02768229777293savings_acctA64\n",
       ":   0.0255915413756812savings_acctA65\n",
       ":   0.0154615584514642employmentA74\n",
       ":   0.0306228021827614installment_rate\n",
       ":   0.000287438807885747sex_statusA93\n",
       ":   0.00376942038236364other_debtorsA103\n",
       ":   0.0534229330140778age\n",
       ":   0.0766817468202007liability_to_other_people\n",
       ":   0.0759716500377071foreign_workerA202\n",
       ":   0.0637794534482211\n",
       "\n"
      ],
      "text/plain": [
       "  status_checking_acctA13   status_checking_acctA14           duration_months \n",
       "             2.056653e-02              1.016001e-10              5.479164e-03 \n",
       "           credit_histA33            credit_histA34                purposeA41 \n",
       "             7.962672e-02              2.439942e-03              3.463831e-05 \n",
       "              purposeA410                purposeA42                purposeA43 \n",
       "             8.732650e-02              1.726545e-03              1.235777e-03 \n",
       "               purposeA48                purposeA49                credit_amt \n",
       "             6.936459e-02              2.975966e-02              2.768230e-02 \n",
       "          savings_acctA64           savings_acctA65             employmentA74 \n",
       "             2.559154e-02              1.546156e-02              3.062280e-02 \n",
       "         installment_rate             sex_statusA93         other_debtorsA103 \n",
       "             2.874388e-04              3.769420e-03              5.342293e-02 \n",
       "                      age liability_to_other_people        foreign_workerA202 \n",
       "             7.668175e-02              7.597165e-02              6.377945e-02 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we try to improve the model by including more features. we increase the p-value threshold from 0.05 to 0.1\n",
    "\n",
    "(summary(logistic_model)$coef[,'Pr(>|z|)'])[(summary(logistic_model)$coef[,'Pr(>|z|)'] <= 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we build a new model with additional features; foreign_worker, other_debtors and liability_to_other_people \n",
    "#  with 0.05 > p-values < 0.1.\n",
    "#  exluding age, will further improve recall but we will include it since it will improve precision while maintaining recall\n",
    "#  this model will improve all metrics compared to the original model with all features\n",
    "\n",
    "improved_logistic_model_2 <- train(credit_risk ~ status_checking_acct + duration_months + credit_hist + purpose +\n",
    "                                   credit_amt + savings_acct + employment + installment_rate + foreign_worker +\n",
    "                                   other_debtors + liability_to_other_people + age,\n",
    "                                   data = trainSet, method = 'glm', family = binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing the model\n",
    "\n",
    "improved_logistic_predict_2 <- predict(improved_logistic_model_2, newdata=testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  Predicted\n",
       "Actual             Good Credit Risk Bad Credit Risk\n",
       "  Good Credit Risk              121              18\n",
       "  Bad Credit Risk                27              34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let us look at the confusion matrix\n",
    "\n",
    "confusion.matrix <- as.matrix(table('Actual'=testSet$credit_risk, 'Predicted' = improved_logistic_predict_2))\n",
    "confusion.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Precision metric of our improved logistic regression model = 0.8373'"
      ],
      "text/latex": [
       "'Precision metric of our improved logistic regression model = 0.8373'"
      ],
      "text/markdown": [
       "'Precision metric of our improved logistic regression model = 0.8373'"
      ],
      "text/plain": [
       "[1] \"Precision metric of our improved logistic regression model = 0.8373\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Recall metric of our improved logistic regression model = 0.8854'"
      ],
      "text/latex": [
       "'Recall metric of our improved logistic regression model = 0.8854'"
      ],
      "text/markdown": [
       "'Recall metric of our improved logistic regression model = 0.8854'"
      ],
      "text/plain": [
       "[1] \"Recall metric of our improved logistic regression model = 0.8854\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'F Score of our improved logistic regression model = 0.8607'"
      ],
      "text/latex": [
       "'F Score of our improved logistic regression model = 0.8607'"
      ],
      "text/markdown": [
       "'F Score of our improved logistic regression model = 0.8607'"
      ],
      "text/plain": [
       "[1] \"F Score of our improved logistic regression model = 0.8607\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the metrics\n",
    "\n",
    "# true positive\n",
    "tp <- sum(confusion.matrix[1,])\n",
    "\n",
    "# true positives + false positives\n",
    "tp_fp <- sum(confusion.matrix[1,], confusion.matrix[2,1])\n",
    "\n",
    "# compute the precision from above formula\n",
    "precision <- tp / tp_fp\n",
    "paste('Precision metric of our improved logistic regression model =', round(precision, 4))\n",
    "\n",
    "# true positives + false negatives\n",
    "tp_fn <- sum(confusion.matrix[1,], confusion.matrix[1,2])\n",
    "\n",
    "# compute recall from above formula\n",
    "recall <- tp / tp_fn\n",
    "paste('Recall metric of our improved logistic regression model =', round(recall, 4))\n",
    "\n",
    "# compute F score from above formula\n",
    "f1 <- 2 * (precision * recall) / (precision + recall)\n",
    "paste('F Score of our improved logistic regression model =', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Metric|Original Logistic Regression model|Improved Logistic Regression Model| Improved Logistic Regression model 2|\n",
    "|---------|-----------------|-------------------------|----------------------|\n",
    "|Precision|0.8274|0.8225|0.8373|\n",
    "|Recall   |0.8528|0.8854|0.8854|\n",
    "|F Score  |0.8399|0.8528|0.8607|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we were able to improve the model further by selecting features that are significant, then dropping features and observing the effect to the metric, keeping only the features that improved the model.<br>\n",
    "We then add more features that has lower significance up to a p-value of 0.1, then again droppping features  and observing the effect to the metrics, keeping only the features that improved the model.<br>\n",
    "We were able to improve all metrics from the original model with this method.<br>\n",
    "* Precision\t- from 0.8274 to 0.8373\n",
    "* Recall    - from\t0.8528 to 0.8854\n",
    "* F Score   - from 0.8399\tto 0.8607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the Naive Bayes model with selected features with p-values <= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build and train the improved naive bayes model using selected features identified ealier\n",
    "# we again exclude sex_status as it lowers the metrics further\n",
    "\n",
    "improved_nb_model <- naiveBayes(credit_risk ~ status_checking_acct + duration_months + credit_hist + purpose +\n",
    "                                credit_amt + savings_acct + employment + installment_rate,\n",
    "                                data = trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test our improved naive bayes model\n",
    "\n",
    "improved_nb_predict <- predict(improved_nb_model, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  Predicted\n",
       "Actual             Good Credit Risk Bad Credit Risk\n",
       "  Good Credit Risk              124              15\n",
       "  Bad Credit Risk                27              34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the confusion matrix\n",
    "\n",
    "confusion.matrix <- as.matrix(table('Actual'=testSet$credit_risk, 'Predicted' = improved_nb_predict))\n",
    "confusion.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Precision metric of our improved naive bayes model = 0.8373'"
      ],
      "text/latex": [
       "'Precision metric of our improved naive bayes model = 0.8373'"
      ],
      "text/markdown": [
       "'Precision metric of our improved naive bayes model = 0.8373'"
      ],
      "text/plain": [
       "[1] \"Precision metric of our improved naive bayes model = 0.8373\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Recall metric of our improved naive bayes model = 0.9026'"
      ],
      "text/latex": [
       "'Recall metric of our improved naive bayes model = 0.9026'"
      ],
      "text/markdown": [
       "'Recall metric of our improved naive bayes model = 0.9026'"
      ],
      "text/plain": [
       "[1] \"Recall metric of our improved naive bayes model = 0.9026\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'F Score of our improved naive bayes model = 0.8688'"
      ],
      "text/latex": [
       "'F Score of our improved naive bayes model = 0.8688'"
      ],
      "text/markdown": [
       "'F Score of our improved naive bayes model = 0.8688'"
      ],
      "text/plain": [
       "[1] \"F Score of our improved naive bayes model = 0.8688\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### compute the metrics\n",
    "\n",
    "# true positive\n",
    "tp <- sum(confusion.matrix[1,])\n",
    "\n",
    "# true positives + false positives\n",
    "tp_fp <- sum(confusion.matrix[1,], confusion.matrix[2,1])\n",
    "\n",
    "# compute the precision from above formula\n",
    "precision <- tp / tp_fp\n",
    "paste('Precision metric of our improved naive bayes model =', round(precision, 4))\n",
    "\n",
    "# true positives + false negatives\n",
    "tp_fn <- sum(confusion.matrix[1,], confusion.matrix[1,2])\n",
    "\n",
    "# compute recall from above formula\n",
    "recall <- tp / tp_fn\n",
    "paste('Recall metric of our improved naive bayes model =', round(recall, 4))\n",
    "\n",
    "# compute F score from above formula\n",
    "f1 <- 2 * (precision * recall) / (precision + recall)\n",
    "paste('F Score of our improved naive bayes model =', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Metric|Original Naive Bayes model|Improved Naive Bayes Model|\n",
    "|---------|-----------------|-------------------------|\n",
    "|Precision|0.8476|0.8373|\n",
    "|Recall   |0.8910|0.9026|\n",
    "|F Score  |0.8688|0.8688|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the table above that our naive bayes model's Recall metric improved after selecting only a subset of the features that we have for building the model. However, the precision metric went lower, meaning the model has become more pessimistic with more false negatives. The F Score remained the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the Naive Bayes model further by adding more features with 0.05 > p-values < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we add features identified earlier to further improve the model\n",
    "# we note that adding or removing age makes no difference so we excluded it for a more simple model\n",
    "\n",
    "improved_nb_model_2 <- naiveBayes(credit_risk ~ status_checking_acct + duration_months + credit_hist + purpose +\n",
    "                                credit_amt + savings_acct + employment + installment_rate + foreign_worker +\n",
    "                                other_debtors + liability_to_other_people,\n",
    "                                data = trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test our improved naive bayes model\n",
    "\n",
    "improved_nb_predict_2 <- predict(improved_nb_model_2, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  Predicted\n",
       "Actual             Good Credit Risk Bad Credit Risk\n",
       "  Good Credit Risk              124              15\n",
       "  Bad Credit Risk                27              34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the confusion matrix\n",
    "\n",
    "confusion.matrix <- as.matrix(table('Actual'=testSet$credit_risk, 'Predicted' = improved_nb_predict))\n",
    "confusion.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Precision metric of our improved naive bayes model = 0.8373'"
      ],
      "text/latex": [
       "'Precision metric of our improved naive bayes model = 0.8373'"
      ],
      "text/markdown": [
       "'Precision metric of our improved naive bayes model = 0.8373'"
      ],
      "text/plain": [
       "[1] \"Precision metric of our improved naive bayes model = 0.8373\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Recall metric of our improved naive bayes model = 0.9026'"
      ],
      "text/latex": [
       "'Recall metric of our improved naive bayes model = 0.9026'"
      ],
      "text/markdown": [
       "'Recall metric of our improved naive bayes model = 0.9026'"
      ],
      "text/plain": [
       "[1] \"Recall metric of our improved naive bayes model = 0.9026\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'F Score of our improved naive bayes model = 0.8688'"
      ],
      "text/latex": [
       "'F Score of our improved naive bayes model = 0.8688'"
      ],
      "text/markdown": [
       "'F Score of our improved naive bayes model = 0.8688'"
      ],
      "text/plain": [
       "[1] \"F Score of our improved naive bayes model = 0.8688\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### compute the metrics\n",
    "\n",
    "# true positive\n",
    "tp <- sum(confusion.matrix[1,])\n",
    "\n",
    "# true positives + false positives\n",
    "tp_fp <- sum(confusion.matrix[1,], confusion.matrix[2,1])\n",
    "\n",
    "# compute the precision from above formula\n",
    "precision <- tp / tp_fp\n",
    "paste('Precision metric of our improved naive bayes model =', round(precision, 4))\n",
    "\n",
    "# true positives + false negatives\n",
    "tp_fn <- sum(confusion.matrix[1,], confusion.matrix[1,2])\n",
    "\n",
    "# compute recall from above formula\n",
    "recall <- tp / tp_fn\n",
    "paste('Recall metric of our improved naive bayes model =', round(recall, 4))\n",
    "\n",
    "# compute F score from above formula\n",
    "f1 <- 2 * (precision * recall) / (precision + recall)\n",
    "paste('F Score of our improved naive bayes model =', round(f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Metric|Original Naive Bayes model|Improved Naive Bayes Model|Improved Naive Bayes Model 2|\n",
    "|---------|-----------------|-------------------------|---------|\n",
    "|Precision|0.8476|0.8373|0.8373|\n",
    "|Recall   |0.8910|0.9026|0.9026|\n",
    "|F Score  |0.8688|0.8688|0.8688|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that by adding the same features that further improved the logistic regression model did not change the efficiency of the naive bayes model further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between improved Logistic Rergression models and improved Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Improved logistic regression and improved naive bayes model comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Metric|Improved Logistic Regression Model|Improved Logistic Regression Model 2|Improved Naive Bayes Model|Improved Naive Bayes Model 2|\n",
    "|---------|-----------------|-------------------------|--------------|---------|\n",
    "|Precision|0.8225|0.8373|0.8373|0.8373|\n",
    "|Recall   |0.8854|0.8854|0.9026|0.9026|\n",
    "|F Score  |0.8528|0.8607|0.8688|0.8688|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the table above that the improved naive bayes model still has better performance compared to the improved logistic regression model as well as the further improved logistic regression model 2, although the precision of the naive based model decreased from the original model that has all features included. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss why having a model with less number of attributes is beneficial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A model with less number of attributes minimises over fitting, thus the model generalise better to unseen data.<br>\n",
    "Additionally, there is less noise from irrelevant or redundant data that gets included in the model.<br>\n",
    "Finally, the model trains faster since it has less features to include in the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3:\n",
    "We will plot a ROC curve for each of the models built in (2) and report its AUC then discuss our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Improved Logistic Regression model AUC = 0.713940323151315'"
      ],
      "text/latex": [
       "'Improved Logistic Regression model AUC = 0.713940323151315'"
      ],
      "text/markdown": [
       "'Improved Logistic Regression model AUC = 0.713940323151315'"
      ],
      "text/plain": [
       "[1] \"Improved Logistic Regression model AUC = 0.713940323151315\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we need to change our predicted data and actuak data into numeric format\n",
    "pred_logistic <- as.numeric(improved_logistic_predict_2)\n",
    "label_logistic <- as.numeric(testSet$credit_risk)\n",
    "\n",
    "# we create a prediction object from our prediction and the actual data\n",
    "roc_pred_logictic <- prediction(pred_logistic, label_logistic)\n",
    "\n",
    "# we creat a performance object using our prediction object and pass arguments, tpr (true positive rate) and fpr (false positive rate)\n",
    "roc_perf_logistic <- performance(roc_pred_logictic, 'tpr', 'fpr')\n",
    "\n",
    "# we plot the ROC\n",
    "plot(roc_perf_logistic)\n",
    "\n",
    "# we show the AUC from the performance function\n",
    "auc_logistic <- performance(roc_pred_logictic, 'auc')@y.values\n",
    "paste('Improved Logistic Regression model AUC =', auc_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Model ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Improved Naive Bayes model AUC = 0.72473169005779'"
      ],
      "text/latex": [
       "'Improved Naive Bayes model AUC = 0.72473169005779'"
      ],
      "text/markdown": [
       "'Improved Naive Bayes model AUC = 0.72473169005779'"
      ],
      "text/plain": [
       "[1] \"Improved Naive Bayes model AUC = 0.72473169005779\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQoIAQoIAQoIAQoIAQoIAQoIAQoIA/wCodgEiW/rcsAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_nb <- as.integer(improved_nb_predict)\n",
    "label_nb <- as.integer(testSet$credit_risk)\n",
    "roc_pred_nb <- prediction(pred_nb, label_nb)\n",
    "roc_perf_nb <- performance(roc_pred_nb, 'tpr', 'fpr')\n",
    "plot(roc_perf_nb) \n",
    "\n",
    "auc_nb <- performance(roc_pred_nb, 'auc')@y.values\n",
    "paste('Improved Naive Bayes model AUC =', auc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Impirically inspecting the ROC curves of both our logistic regression and naive bayes models, it is difficult to comapre which one has better performce.<br>\n",
    "However, the AUC shows that naive bayes, with AUC = 0.725, has better performance than the logistic regression model, which has AUC = 0.714.<br>\n",
    "We also see that before a certain theshold, both models make more true positive predictions than false positive ones, that is, the ratio of true positives over false positives is higher.<br>\n",
    "Until reaching a threshold where the performance suddenly diminishes.<br>\n",
    "Finally, we can also see from the ROC and AUC results that both models are better than a random classifier but still has room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4\n",
    "By default, there are approximately 30% bad customers in the data. We will downsample bad customers to only 30 in the training data, and build a logistic regression and a naive Bayes using the same predictors selected in (2). We will then plot the ROC curves and compute the AUC and explain the models' performance for imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with down sampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "30"
      ],
      "text/latex": [
       "30"
      ],
      "text/markdown": [
       "30"
      ],
      "text/plain": [
       "[1] 30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# down sample bad customers from 30% to 30 in trainSet data\n",
    "\n",
    "# we get the row numbers with credit risk equals 'Bad Credit Risk'\n",
    "bad_risk_index <- which(trainSet$credit_risk == 'Bad Credit Risk')\n",
    "\n",
    "# we get the number of samples we need to update to 'Bad Credit Risk'\n",
    "n_samples_to_update <- sum(table(bad_risk_index)) - 30\n",
    "\n",
    "# we create a new test dataset that has imbalanced data and will call it trainSet_imbalanced\n",
    "# we randomly sample row numbers with 'Bad Credit Risk' in them and remove them fro the data set\n",
    "# we use set.seed() so that our values don't change\n",
    "\n",
    "set.seed(5197)\n",
    "trainSet_imbalanced <- trainSet[-sample(bad_risk_index, n_samples_to_update),]\n",
    "\n",
    "# we check that we only have 30 rows that has 'Bad Credit Risk'\n",
    "sum(table(which(trainSet_imbalanced$credit_risk == 'Bad Credit Risk')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\""
     ]
    }
   ],
   "source": [
    "# build logistic model based on variables above\n",
    "improved_logistic_model_2 <- train(credit_risk ~ status_checking_acct + duration_months + credit_hist + purpose +\n",
    "                                   credit_amt + savings_acct + employment + installment_rate + foreign_worker +\n",
    "                                   other_debtors + liability_to_other_people,\n",
    "                                   data = trainSet_imbalanced, method = 'glm', family = binomial)\n",
    "\n",
    "# testing the model\n",
    "improved_logistic_predict_2 <- predict(improved_logistic_model_2, newdata=testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  Predicted\n",
       "Actual             Good Credit Risk Bad Credit Risk\n",
       "  Good Credit Risk              136               3\n",
       "  Bad Credit Risk                55               6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the confusion matrix\n",
    "confusion.matrix <- as.matrix(table('Actual'=testSet$credit_risk, 'Predicted' = improved_logistic_predict_2))\n",
    "confusion.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Improved Logistic Regression model AUC = 0.538388960962378'"
      ],
      "text/latex": [
       "'Improved Logistic Regression model AUC = 0.538388960962378'"
      ],
      "text/markdown": [
       "'Improved Logistic Regression model AUC = 0.538388960962378'"
      ],
      "text/plain": [
       "[1] \"Improved Logistic Regression model AUC = 0.538388960962378\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nEBIEEBIEEBIE+AdJVw1DoTsVXwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_logistic <- as.integer(improved_logistic_predict_2)\n",
    "label_logistic <- as.integer(testSet$credit_risk)\n",
    "roc_pred_logictic <- prediction(pred_logistic, label_logistic)\n",
    "roc_perf_logistic <- performance(roc_pred_logictic, 'tpr', 'fpr')\n",
    "plot(roc_perf_logistic)\n",
    "\n",
    "auc_logistic <- performance(roc_pred_logictic, 'auc')@y.values\n",
    "paste('Improved Logistic Regression model AUC =', auc_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes with down sampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build and train the improved naive bayes model using selected features\n",
    "improved_nb_model <- naiveBayes(credit_risk ~ status_checking_acct + duration_months + credit_hist + purpose +\n",
    "                                credit_amt + savings_acct + employment + installment_rate,\n",
    "                                data = trainSet_imbalanced)\n",
    "\n",
    "# test our improved naive bayes model\n",
    "improved_nb_predict <- predict(improved_nb_model, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  Predicted\n",
       "Actual             Good Credit Risk Bad Credit Risk\n",
       "  Good Credit Risk              134               5\n",
       "  Bad Credit Risk                53               8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the confusion matrix\n",
    "confusion.matrix <- as.matrix(table('Actual'=testSet$credit_risk, 'Predicted' = improved_nb_predict))\n",
    "confusion.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Improved Naive Bayes model AUC = 0.547588158981012'"
      ],
      "text/latex": [
       "'Improved Naive Bayes model AUC = 0.547588158981012'"
      ],
      "text/markdown": [
       "'Improved Naive Bayes model AUC = 0.547588158981012'"
      ],
      "text/plain": [
       "[1] \"Improved Naive Bayes model AUC = 0.547588158981012\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_nb <- as.integer(improved_nb_predict)\n",
    "label_nb <- as.integer(testSet$credit_risk)\n",
    "roc_pred_nb <- prediction(pred_nb, label_nb)\n",
    "roc_perf_nb <- performance(roc_pred_nb, 'tpr', 'fpr')\n",
    "plot(roc_perf_nb)\n",
    "\n",
    "auc_nb <- performance(roc_pred_nb, 'auc')@y.values\n",
    "paste('Improved Naive Bayes model AUC =', auc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Models' performance for imbalanced data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that with imbalanced data, both logistic regression and naive bayes models' performance went down to  just around 0.538 to 0.548 in terms of AUC, respectively.<br>\n",
    "We also see that with imbalanced data, our models performs just a little bit better than a random classifier, whose AUC = 0.5.  \n",
    "Finally, Looking at the confusion matrix, the imbalanced data turned both our models into very optimistic models that has high levels of false positives.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
